# event_cluster

## 1. 利用OpenHowNet进行谓宾聚类
先计算整个谓宾短语在OpenHowNet中的义原，然后再根据丁校的方法进行相似度的计算，但是发现大部分的谓宾短语都识别不出来，因此计划下一步使用**宾语相似度与谓语相似度分开计算的方式**来进行聚类

## 2. 利用Phrase2Vec进行聚类
> https://blog.csdn.net/flyfrommath/article/details/79643233

### 2.1 数据过滤和模型加载

#### 2.1.1 使用Hanlp中的Doc2vec
利用**FastText\wiki.zh.vec**能够得到短语向量的一共有73013个，不能够得到的有6448条<br>
而利用**腾讯AI词向量精简版-1000000-small.txt**能够得到的短语向量一共有78165个，不能够得到的有1296个，如果利用**腾讯AI完整的词向量应该能够得到更多**

#### 2.1.2 使用Gensim中的Word2Vec，对谓宾分别计算词向量，然后再做一次平均
利用**FastText\wiki.zh.vec**能够得到的短语向量有51558个，不能够得到的有27903个，可以看到的是这样的方法与把谓宾当作整体的方法来看效果并不是特别好<br>
利用**腾讯AI词向量精简版-1000000-small.txt**能够得到的短语向量一共有74908个,不能够得到的有1296个<br>
利用**百度百科word2vec_baike**能够得到73840个有效的短语向量,不能够得到的有5620个


## 3. 利用Hanlp提供的文本聚类工具进行训练
输入的是一系列谓宾短语，从输出的结果看，大部分聚的类都是**谓语一致**，**宾语不同**的情况，但是也有着**谓语不一致**，**宾语一致**的情况，比如

```JSON
    [
        "吃 芝麻饼",
        "吃 麦饼筒",
        "吃 饼",
        "吃 软饼",
        "吃 薯饼",
        "吃 饼饼"
    ],
    [
        "吃 芝麻饼",
        "吃 麦饼筒",
        "吃 饼",
        "吃 软饼",
        "吃 薯饼",
        "吃 饼饼"
    ],
    [
        "乘 公交车",
        "入住 公交车",
        "就是 公交车",
        "遍布 公交车",
        "开来 公交车",
        "赶 公交车",
        "靠 公交车",
        "上有 公交车"
    ],
        [
        "订到 机票",
        "订好 机票",
        "查 机票",
        "预订 机票",
        "到 机票",
        "搜 机票",
        "看 机票",
        "就是 机票",
        "优于 机票"
    ],

```

这样就是把之前宾语聚类的结果给做了进一步的细化,从78000条数据中一共分出来6336个类

## 4. 利用Phrase2Vec已经训练好的词向量和K-means进行训练

### 4.1 类个数的确定
由于训练的一次的时间过长，因此可以设置在7000类左右

### 4.2 谓宾要比谓语好的地方
分类的结果应该跟hanlp训练的效果一样，因此要加大类的数量



# 4. 未来要做的

1. 动词的词性做进一步的过滤，比如
> 称为 称作 
这些都是动词，但是再旅游领域并没有实际的意义

2. 大量游记进行词向量的训练
GPU训练

3. 旅游领域的一些常用名词（景点除外），来判断主语不同的时候谓宾的情况

4. 谓语动词的聚类

5. 文件命名
- 向量文件
- 聚类结果文件
> 需要声明用了哪个库和哪个向量



# 5. 整个项目的代码结构
## 5.1 文本爬取模块
## 5.2 文本解析模块
## 5.3 解析结果存储模块
## 5.4 聚类模块
### 5.4.1 谓语聚类模块
#### 5.4.1.1 HowNet-dx
#### 5.4.1.2 Word2vec
### 5.4.2 谓语宾语聚类模块
#### 5.4.2.1 谓语宾语当成一个整体来聚类
##### 5.4.2.1.1 HowNet-dx
##### 5.4.2.1.2 Phrase2vec(hanlp)+K-means
##### 5.4.2.1.3 Hanlp文本聚类
##### 5.4.2.1.4 Doc2vec(gensim) + K-means
#### 5.4.2.2 谓语宾语分开计算相似度
### 5.4.3 主谓宾聚类模块

    

# 6. 加速技巧
1. pip豆瓣源
```sh
pip install package_name -i http://pypi.douban.com/simple --trusted-host pypi.douban.com
```

2. Tensorflow实现K-means
- https://blog.csdn.net/qq_30615903/article/details/80997232
- https://www.jianshu.com/p/c1caccafd2d6
